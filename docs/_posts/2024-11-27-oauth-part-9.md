---
layout: post
title:  "Oauth Part 9 OAUTH"
date:   2024-11-27 00:00:00 +0000
categories: tech oauth
---

I'm continuing to read RFC 6819 in this post. Section 4 and 5
have to do with the threat model and mitigations, so as I write this,
I might be switching back and forth between those two sections

The RFC says that it divides the treat model according to the role
being discussed -- that is, resource server, client, and auth server --
and then is further divided into different flows.

It is assumed in this RFC that the attacker has a lot of access. It
says that it is assumed that an attacker can view traffic between
client and auth server and between client and resource server, but
it is not assumed that an attacker has network access between
resource server and auth server.

Personally, I think this is an odd distinction, but it's illustrative
of the environment that the authors have in mind. I think the auth
server and resource server role are thought to be professional
installations, perhaps being operated by the same company. On the other
hand, a client might be run on the user's own and maybe on some sketchy
public wifi with a hooded hackerman lurking in the corner running
tcpdump.

# Threat: Obtaining client secrets

client secrets are the credential the client uses to authenticate
itself with the auth server. If the cleint secret were to be exposed,
it would enable an attacker to impersonate the client. The RFC tells
us the attacker would be able to replay auth codes or refresh tokens
to obtain access tokens that were not authorized by the owner.

It suggests that the cient secret might be obtained if it is compiled
into any distributed material, and explains that even if the secret
is obsfucated, it would eventually still be discovered by reverse
engineering efforts.

I'd say this is obviously true. Don't compile secrets into your
application and distribute it out to people. The RFC gives us more
countermeasures.

* Don't issue secrets to public clients.
* Require user concent for public clients
* Use deployment-specific client secrets
* Revoke client secrets

and these are spelled out in more detail in section 5.

It tells us not to distribute client code with a secret compiled in
because it (obviously) exposes the secret to anyone who cares to
look for it, and also it makes it impossible to revoke the secret.

What do we do about public clients such as native clients? 5.2.3.4
tells us this is a more complex process, but I've seen this before.
Basically, this will require users to register for some kind of key
and put key into their client. The exact mechanism isn't explained,
and there are probably many good ways to do this. Put it in a config
file, or send the user through a sign-up process during install.

Finally, revoke client secrets. If you detect any kind of possible
misuse, revoke the client and make the client sign up again.


# Threat: Obtaining deployment specific secrets

Secrets have to be stored somehow. The RFC doesn't give any good
advice for this. Just protect your secrets somehow. It says for
native applications, store it in secure storage. This honestly
seems more feasible on smartphones than servers or desktops.
You want to store the secrets in a way other applications can't
easily access them


# Threat obtaining refresh tokens

Refresh tokens can be used to obtain more access tokens, so we need
to keep these secret. 

The authorization should be able to tie the refresh token to a
particular client, this way leaking the refresh token is not sufficient
for an attacker to obtian unauthorized access, they'd need to know
the secret as well.

Tokens should be limited in scope to reduce the blast radius.

It gives a suggestion to rotate refresh tokens and use this as a method
to detect fraud. If you change the refresh token, and then you see
an older token being used, this might mean you have a refresh token
leakage problem. You might not be able to tell which client is real and
which is illegitimate, but you can tell that something is off.
You see an old token in use, this should trigger a revocation for all
the tokens issued.

a new refresh token for every request is a good idea.
It's kind of a nonce for tokens. I could imagine
other mechanisms that would accomplish something similar. In my mind,
I'm thinking of those physical RSA tokens that generate a number once
per minute with seeded PRNG. You could store the seed and generate a
unique token that can't be replayed. But I guess then you'd still have
the problem of storing the seed so maybe that's not such a great
solution after all.


# Stolen devices

what do we do when a device is stolen?

Well, this is why we need to be able to revoke client codes.
Device is reported stolen, revoke all the keys issued to that client.

Allow users to revoke their own tokens.

# Cloned devices

A cloned device will have a copy of all the secrets on the device.

Fire your maid. But first, the auth server should have been doing the
refresh-token-per-request thing, so you should be able to detect
that two devices use the same  refresh token and revoke everything.


# Obtaining access tokens

Access tokens need to be short lived, and basically don't store them
at all except in ephemeral memory, and if you do store them, put them
only in secure storage.


# Embedded browsers.

Imagine you have installed an application on your phone and it takes
you to log in using an embedded web browser interface. Except, it's
not a real web browser, it's a spoofed browser that just captures
your username and password.

There isn't really a good mitigation for this, and am not sure that
there could be. The only mitigation listed in the RFC is that
it's not required for users to put in their password to authenticate
clients and you could train users to be suspicious if they see this.
That's not much of a mitigation, if you ask me.

Another mitigation is that maybe applications could be vetted. I think
the authors are thinking of the google play store or the apple app
store when they wrote this. Again, not a great mitigation, but I can
not think of anything much better myself.

I think it's interesting to see this here, since embedded browsers
were explicitly a feature for auth and implicit flows for native
clients in the oauth 2.0 standard.

# Open redirectors

Imainge you put the redirect_url to something wacky. You could
accidently expose our auth code to a malicious applicaiton.

The mitigation for this is to require clients to register redirect
URIs with the auth server. The auth server should decline to process
authorization requests with an unusual redirect URI.

# Authorization endpoints

How do you prevent the auth endpoint from being spoofed?

There isn't much about this mitigation, except that it relies on the
network. 4.2.1 suggests that DNS or ARP spof ing might be used to
to impersonate the auth server, so what do we do?

Trust the lock icon.
Educate users about TLS, and use TLS on your auth server.

# User grants too much access scope

Again no mitigation. Just don't ask for too much scope.

# malicious client obtains existing authorization by fraud.

The idea behind this attack is this:

To avoid annoying the user, some auth servers might only prompt
the user for approval the first time, and for subsequent approvals for
the same client, the auth server will simply redirect the user back
to the client without the "do you allow this" prompt.

A second, malicious client might try to take advantage of this. The
malicious client directs the user throught he auth process and supplies
the the redirect_uri that will direct the client back to itself, where
it can extract the auth code.

I think this attack is easy to mitigate for clients that have a client
secret, and damn near impossible to mitigate for public clients.

A public cient will have no secret, is unauthenticated, and might
have a redirect_uri that points to localhost. What software is listing
on that local host is anybody's guess. It might be the real client, or
it might be a malicious client.

The RFC says authorization servers shouldnot automatically process
authorizations to public clients unless the client is validated
using a pre-registred redirect URI. In my opinion, if the client is a
server applicaiton, that server should really not be a public client.

The only real mitigation I see for this attack is to limit the scope
that can be obtained through automated approvals. But personally, I
think this is a confusing mitigation. Imagine setting up some software
and it works flawlessly, and then later, after your token expires, you
go through an "automated" authorization where the client obtains a
new access token with a reduced scope and the software now doesn't
work correctly.

I think this would have to be paired with some kind of user
notification. The client would have to notify the user that "feature
X, Y, Z has been suspended, would you like to authorize again?"

To me, the real mitigation is to just don't use a public client, this
way if you do accidently leak the auth code, it won't be usable.

# Access token leakage through the Token endpoint

Use TLS

# Obtaining access token from the authorization server

The auth server is probably storing the tokens somehow, like in a
database.

Mitigate this issue by normal mechanisms that prevent database
access. Friends don't let friends exfiltrate their database through
SQL injection. All that. 

Also, it suggests only storing the hashes of. This recommendation
points us to 5.1.4.1.3 which explains this mitigation is actually
to store the token in an encrypted form.

I'm going off the cuff here, but it would make no difference if you had
a dabase filled with encrypted data where the encryption key was stored
in the same database, so I suppose you would need have an additional
encryption key stored in yet another database.
Another idea is to store just the hashes. Storing just the hashes, to 
me, is a bit odd if you think about what the token actually is.

The token is just a SAML, XML, or JSON document. In these formats,
changing the order would be equivilent.

For example {"a": 1, "b": 2} is equivilent to {"b": 2, "a": 1}, but
after you've gone through all the encodings the two representations
will have different hash values. If you store only the hashes, then
you've rendered all the other representations invalid, even though
they have the same assertions.

If the tokens are signed, I wonder if it would be better to store
*signatures* rather than *hashes*. but then again, maybe not, since
at some level the tokens are just opaque strings. 


# Client secrets exposed through auth server database

Again, a databse thing. Use good database security and don't allow
SQL injections.

# Obtain client secret through online guessing

Basically, you need to notice if someone is trying to guess the client
secret and lock their account. That, and use high entropy secrets,
and if possible avoid transmitting the secret at all using MAC.

For that matter, I think just use a gigantic crypto key.

The RFC says you can avoid the need to distribute a client secret
using OAuth-ASSSERTIONS. and there is a reference for that, and it's in
RFC7521

# Leaking authorization codes.

The RFC doesn't give a lot of information about mitigating attacks
involving a misbehaving web browser, but it just suggests if you have
problems that you can look at logs or browser history to figure out
what's happening.

The same mitigations are repeated. Auth servers should detect token
re-use and revoke authorizations for all associated tokens.


# User Session Impoersonization.

The idea is that if an attacker can see a session with a client,
they can impersonate the user. To prevent an attacker from 
impersonating an end-user, use HTTPS for redirection.


# Authorization code leakage through counterfeit client

The idea behind this attack is that an attacker sets up their own
counterfeit client website and by editing the redirect URIs.

The attacker connects to the client and gets the redirect to the auth
server. Remember that this part of the flow will have redirect_uri.
Instead of following the redirect, it will modify the redirect uri
to point at the malicious site and then somehow get a victim to follow
the link.

The victim will click accept, and will be redirected to the attacker's
spoof website. But by that time it's too late, they've now just
passed an auth code to the attacker's website.

The attack site now takes this real auth code and injects it into its
own user agent so that now the access request is associated with the
attacker's login.

To mitigate this attack, the auth server should only allow redirects
to urls that are setup at client registration.


# CSRF

CSRF attacks on oauth approvals allow an attacker to obtain
authorization on to oauth protected resources without concent of the
user.

The RFC says in this attack, the attacker will get get an auth code
to access resources that the attacker owns, and then it will convince
the victim to follow the redirect so the victim has access to the
attacker's protected resources.

The attacker is using the victim to access resources. It says this
style attack, a victim might upload their private data to the attacker's
protected resource.

When using oauth in 3rd party login, the victim may associate his
client account with the attacker's identity as an external IDP. Later,
the attacker can login themselves and make use of the client.

This is a very well known oauth attack. The countermeasures are
detailed in section 5.3.5. It's important to know this one if you
are writing a client.

The mitigation goes something like this.

When first constructing the redirect in the auth flow, clients
can add a "state" value in the URL params. The same state will be
copied back when the client redirects back.

Use this state value to bind the request to particular session.
e.g. use a session cookie, and bind the state in the session cookie.


# Clickjacking attack

A malicious site puts a transparent frame over the visible frame and
tricks the user to clicking an authorize button they aren't aware of.


Mitigations for this one are, hopefully the web browser will obey the 
X-FRAME-OPTIONS header. If not, then it's un-mitigated.


# Social logins

Some services, like google, github, etc. Offer user information
over an API. A client might believe that access to user information
constitutes a user login. A malicious app captures an access token
for one of these services and transmits the access token to the
attacker. The attacker can then use this token to access the identity
API and the client will believe they are logged in.


The counter measure is to use OpenID or SAML to implement user login.


# Resource Owner password Credentials.

Don't do it. You don't need the user's password.

Loads of problems are associated with this method. Just don't do it.


# Accessing protected resources.

Now we're talking about the interaction between client and resource
server.

# Token exposure

This is the same as before, so I'm not going to elaborate again.
Use TLS. Use authentication. Don't print out tokens in logs and then
distirbute those logs to all of your friends.


# Conclusion

This has been a long read, but I learned a lot.

Let me list out a few of the things discussed before they escape my
tired mind.

TLS everywhere, and hopefully end-to-end.
DNSsec to help prevent spoofing
Token rotation helps you detect malicious activity
Deploy CSRF mitigation on your clients.
Encryption at rest for saved secrets.
Clients should map between sessions and auth codes
Auth servers should map between clents and auth codes and tokens
No secrets in log files.
Identity providers are not necessarially logins.
Beware of token swapping attacks.


In the next installment, I'll learn about using JWTs as an oauth token
